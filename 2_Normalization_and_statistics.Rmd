---
title: "Normalization and Statistical Analysis"
author: "Christian Ayala"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
editor_options:
  chunk_output_type: console
---

This Notebook is to perform normalization of the area under the curve (AUC) of the peaks detected by *Compound Discoverer*.

# 1. Importing Libraries

```{r libraries, message=FALSE}
library(tidyverse)
library(readxl)
library(ggpubr)
library(ggsci)
library(gridExtra)
library(vegan)
source('functions_cdis_norm_stats.R')
```

# 2. Import data

The input data is the **compounds-table** generated by the previous scripts

```{r set_path, message=FALSE}
# set path variables
project_dir <- getwd()
project_name <- 'Bog_labeled_1.7int'
figures_dir <- file.path(project_dir, paste0(project_name, '_output_figures'))
tables_dir <- file.path(project_dir,  paste0(project_name, '_output_tables'))
compounds_table_file <- file.path(tables_dir, 'compounds_table.csv')

# Load compounds_table

compounds_table <- read_csv(compounds_table_file)

# Import metadata and fix names
metadata_file <- file.path(tables_dir, 'fixed_metadata.csv')
metadata <- read_csv(metadata_file)

```

# 3. Data Manipulation and Transformation

```{r Data_manipulation}
# Create a new tibble with the AUC per each mass from each sample
auc_table <- compounds_table %>% 
  select(FeatureID, SampleID, AUC)

# Transform the dataframe into a matrix-like table

auc_table <-  spread(auc_table, SampleID, AUC)
auc_table$FeatureID <- factor(auc_table$FeatureID, levels = str_sort(auc_table$FeatureID, numeric = TRUE))
auc_table <- auc_table %>% 
  arrange(FeatureID)


# Save untransformed data

auc_table <- column_to_rownames(auc_table, var = 'FeatureID')

table_file <- file.path(tables_dir, 'raw_auc_table.csv')
write.csv(auc_table, table_file, row.names = TRUE)

```

# 4. Data Normalization by multiple methods

Data is normalized by multiple methods to decide

```{r Data_normalization}

normalization_plot <- normalize_by_all(auc_table)

figure_file <- file.path(figures_dir, 'all_normalized.boxplot.png')
ggsave(figure_file, normalization_plot, dpi = 300)

```

Based on the plot select the best normalization method for the sample.
In this case the best normalization method was **LOESS normalization**


```{r Best normalization}

norm.matrix <- cycloess.norm(auc_table)

```

# 5. Statistical Analysis

## 5.1 NMDS 

```{r nmds}



```


## 5.2 PERMANOVA

Permutational Multivariate Analysis of Variance Using Distance Matrices

```{r Permanova}

# This portion of the script comes from the MetaboTandem pipeline

# Change missing values for zeroes

norm.matrix[is.na(norm.matrix)] <- 0

# distance matrix - bray
dm <- vegdist(t(norm.matrix), method="bray")

metadata <- column_to_rownames(metadata, var = 'SampleID')

set.seed(456)
permanova <- adonis(dm ~ Time + Material + Label, 
                    data=metadata, 
                    permutations=999, 
                    method="bray")
permanova


```

The AUC at different time points contribute to 56% of the differences among the samples

## 5.3 Feature contribution

Explore to determine which features are driving the difference in time

```{r Feature contribution}

# Comparisons are done in pairs

# Comparing based on the sample origin (litter or peat_litter)

sub_metadata <- metadata %>% 
  filter(Time == 'T0' | Time == 'T3')

sub_norm.matrix <- select(norm.matrix, rownames(sub_metadata))

test <- 'Time'
set.seed(456)
# LEAFLIFE; adonis tests homogeneity of dispersion among groups
p.Time <- adonis(t(sub_norm.matrix) ~ Time, 
                data=sub_metadata, 
                permutations=999, 
                method="bray")
p.Time

p.Time.features <- coefficients(p.Time)['Time1',]
p.Time.features <- p.Time.features[rev(order(abs(p.Time.features )))]
p.Time.features <- as.data.frame(p.Time.features) 
colnames(p.Time.features) <- paste0(test, '.f.contrib')
p.Time.features <- signif(p.Time.features, 2)
p.Time.features$Features <- rownames(p.Time.features) #NEGATIVE = Drives T3, POSITIVE = Drives T0


t2 = quantile(abs(p.Time.features$Time.f.contrib), 0.60)
t2
p.Time.features.g <- mutate(p.Time.features,
                            Group = if_else(abs(Time.f.contrib)<t2, 'low contribution',
                                                if_else(Time.f.contrib>t2, 'T0', 'T3')))

file_table <- (file.path(tables_dir, 'features_contribution_T0vsT3.csv'))
write_csv(p.Time.features.g, file_table)
Time.contrib <- 
  p.Time.features.g %>% 
  filter(abs(Time.f.contrib)>t2) %>% 
  ggplot(aes(x = reorder(Features, Time.f.contrib), y = Time.f.contrib, fill = Time.f.contrib > 0)) +
    geom_bar(stat="identity", width = 1, color='black', size=0.1, alpha=0.6) +
    scale_fill_jama(labels = c('T3', 'T0')) +
  theme_bw() +
  labs(title = 'Feature contribution to the difference observed at different times',
       x = 'MS Features',
       y = 'Contribution',
       fill = 'Drives:') +
  theme(plot.title = element_text(face = 'bold',
                                  hjust = 0.5),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank())
  

Time.contrib

figure_file <- file.path(figures_dir, 'Contribution in time.png')
ggsave(figure_file, Time.contrib, dpi = 300)

```

